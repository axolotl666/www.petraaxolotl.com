---
title: "Lie Algebras in Particle Physics"
Description: "Errata, Notes, and Problem Solutions to Lie Algebras in Particle Physics"
date: 2017-01-02T14:59:31-08:00
---

This is a great book. However, a better book for beginners may be Zee's _Group Theory in a Nutshell for Physicists_. Zee's book is mathematically
less rigorous and sometimes made me cringe a bit. But it has a much better overview of finite groups, which are quite important for a beginner to
build intuition. It also covers Lorentz's group, which is obviously important for special relativity and quantum field theory.

# Errata and Notes

## Chapter 1

### 1.4 Irreducible representations

#### Eq. (1.10)

It would be much easier if we were talking about (unitary) matrices instead of (unitary) operators. The former can be considered independent
entities and we are free to do similarity transformations. The latter operates on vectors, which usually have pre-defined concepts such as inner
products (and therefore orthogonality). In this sense, we cannot make a non-unitary operator unitary through a similarity transformation.
We can only make the matrix form of a non-unitary operator unitary by choosing a non-orthonormal basis. But this does not make the operator
itself unitary.

Since $$ S $$ in Eq. (1.10) is in general not unitary, two equivalent representations do not just differ by *a trivial choice of basis*
physically. 

#### Definition of reducibility

The defintion of reducible representations should be those that have a *non-trivial* invariant subspace. Obviously $$ \\{ 0 \\} $$ and the
original vector space are always invariant subspaces for any representations.

#### Eq. (1.13)

The statement that *$$ D_j(g) $$ is irreducible* implies that $$ D_j(g) $$ should be understood as an operator defined on a non-trivial
subspace $$ X_j $$ of the original space $$ X $$, and $$ X_i $$ and $$ X_j $$ are orthogonal to each other for $$ i \neq j $$
and $$ \cup_j X_j = X $$.

### 1.9 Useful theorems

#### Theorem 1.1

$$ U $$ is implicitly assumed to be unitary in Eq. (1.28) and this guarantees that $$ X $$ is hermitian in Eq. (1.31). The proof that a unitary
$$ U $$ always exists to diagonalize a hermitian matrix can be found in most QM books. In fact $$ U $$ can be simply made of orthonormal
eigenvectors of $$ S $$ juxtaposed next to each other.

#### Theorem 1.2

The proof implicitly uses the following fact.

*If two representations $$ D_1 $$ and $$ D_2 $$ are equivalent, $$ D_1 $$ is reducible if and only if $$ D_2 $$ is reducible.* The proof is
as follows.

If $$ D_1 $$ is reducible, there exists a non-trivial subspace $$ X $$ whose projector $$ P $$ satisfies Eq. (1.11)

$$ P D_1(g) P = D_1(g) P, \forall g \in G. $$

Since $$ D_1 $$ and $$ D_2 $$ are equivalent, there exists an invertible transformation $$ S $$ such that
$$ D_1(g) = S^{-1} D_2(g) S, \forall g \in G $$, therefore

$$ P S^{-1} D_2(g) S P = S^{-1} D_2(g) S P, $$

or equivalently

$$ S P S^{-1} D_2(g) S P S^{-1} = D_2(g) S P S^{-1}, $$

where $$ S P S^{-1} $$ is the projector of subspace $$ S X $$, which has the same dimensionality of the original invariant subspace $$ X $$.
Obviously $$ S X $$ is non-trivial since there exists $$ v \not \in X $$ and it is easy to show that $$ S v \not \in S X $$. This proves that
$$ D_2 $$ is also reducible.

Similarly, one can easily prove that if two representations $$ D_1 $$ and $$ D_2 $$ are equivalent, $$ D_1 $$ is completely reducible
if and only if $$ D_2 $$ is completely reducible.

### 1.10 Subgroups

The statement *Every element of $$ G $$ must belong to one and only one coset* is made without proof. The *one* part is rather obvious since
$$ e $$ must be in the subgroup. Below is the proof of the *only one* part.

Assuming that $$ x \in H g_1 $$ and $$ x \in H g_2 $$, we want to prove that $$ H g_1 = H g_2 $$ by showing that $$ H g_1 \subset H g_2 $$ and
$$ H g_2 \subset H g_1 $$.

There must exist $$ x_1 \in H $$ and $$ x_2 \in H $$ such that $$ x = x_1 g_1 = x_2 g_2 $$. This implies that $$ g_1 = {x_1}^{-1} x_2 g_2 $$.

For any $$ y \in H g_1 $$, there exists $$ y_1 \in H $$ such that $$ y = y_1 g_1 = y_1 {x_1}^{-1} x_2 g_2 $$. Note that $$ y_1 $$,
$$ {x_1}^{-1} $$ and $$ x_2 $$ are all elements of $$ H $$ and therefore $$ y_1 {x_1}^{-1} x_2 \in H $$ and $$ y \in H g_2 $$. This proves
$$ H g_1 \subset H g_2 $$.

$$ H g_2 \subset H g_1 $$ can be proved similarly.

### 1.11 Schur's lemma

#### Theorem 1.3

In the proof it is rather hand-waving to simply state *A similar argument shows that $$ A $$ vanishes if there is a $$ \langle v| $$ which
annihilates $$ A $$*, because it actually requires the irreducibility of $$ D_1^\dagger $$ rather than that of $$ D_1 $$ itself and thus
the following fact.

*A representation $$ D $$ is reducible if and only if its Hermitian conjugate $$ D^\dagger $$ is reducible.*

The proof is as follows. Note that this proof does not require $$ D $$ to be a representation of a finite $$ G $$. It is equally valid
even if $$ G $$ is infinite.

If $$ D $$ is reducible, there is a non-trivial subspace $$ S $$ such that its projector $$ P $$ satisfies $$ P D(g) P = D(g) P, \forall g \in G $$.

Notice that the complementary subspace of $$ S $$ is also non-trivial, and $$ I - P $$ is the projector onto it. We have

$$
\begin{eqnarray}
&& (I - P) D^\dagger (g) (I - P)  \\
&=& [(I - P) D(g) (I - P)]^\dagger  \\
&=& [(I - P) D(g) - I D(g) P + P D(g) P]^\dagger  \\
&=& [(I - P) D(g)]^\dagger  \\
&=& D^\dagger (g) (I - P).
\end{eqnarray}
$$

This proves that $$ D^\dagger $$ is also reducible. The *if* part can be proved similarly. 

#### Clarification on Eq. (1.46)

There can be multiple appearances of the same irreducible representation in the block diagnoal form of $$ D $$. They share the same lable $$ a $$
and is distinquished by different values of $$ x $$.

### 1.14 Eigenstates

As for why (1.104) is valid, refer to the derivation up to Eq. (1.57).

### 1.16 Example of tensor products

It is worth noting that $$ D_2 $$ as in (1.109) gives us reflections and rotations.

### 1.17 *Finding the normal modes

Eq. (1.115): The two $$ -\frac{\sqrt{3}}{6} $$ in the last column should be both $$ -\frac{1}{6} $$.

## Chapter 2

Note that when the author talks about a *unitary representation of the algebra*, he really means that the representation of the
group is unitary (and therefore the representation of the the algebra is hermitian).

### Eq. (2.36)

Note that when the group representation is unitary (or equivalent to a unitary representation), $$ T_a $$ is hermitian (or equivalent
to a hermitian matrix). So we have $$ \mathrm{Tr} (T_a T_a) \ge 0 $$.

### Eq. (2.39)

Typo. $$ \mathrm{Tr} $$ is missing before two pairs of parentheses.

# Solutions

## Chapter 1

### 1.A.

Trivial. Simply use the fact that every element appears once and only once in every row and column of the multiplication table.

### 1.B.

The only two possibilities are given below, corresponding to $$ Z_4 $$ and $$ Z_2 \times Z_2 $$ respectively.

$$
\begin{array}
\hline
 e & a & b & c  \\ \hline
 a & b & c & e  \\ \hline
 b & c & e & a  \\ \hline
 c & e & a & b  \\ \hline
\end{array}
$$

$$
\begin{array}
\hline
 e & a & b & c  \\ \hline
 a & e & c & b  \\ \hline
 b & c & e & a  \\ \hline
 c & b & a & e  \\ \hline
\end{array}
$$

### 1.C.

If the representation (1.135) of the permutation group is irreducible, (1.79) would apply.

### 1.D.

Applying Schur's lemma, we have $$ S^{-1} A = \lambda I $$, or $$ A = \lambda S $$.

### 1.E.

It is essentially the group $$ A_4 $$, made of permutations with an even number of 2-cycles. There are in total $$ 4! / 2 = 12 $$ elements.

There are four conjugacy classes.
- {e},
- {(12)(34), (13)(24), (14)(23)},
- {(123), (243), (134), (142)},
- {(132), (234), (143), (124).

From (1.74), we know the four irreducible representations must be of 1-, 1-, 1-. and 3-dimensional. By applying (1.79) and (1.87), we get the
following character table.

$$
\begin{array}
\hline
 \text{} & e & (12)(34) & (123)    & (321)     \\ \hline
 D_1     & 1 & 1        & 1        & 1         \\ \hline
 D_{1'}  & 1 & 1        & \omega   & \omega^2  \\ \hline
 D_{1''} & 1 & 1        & \omega^2 & \omega    \\ \hline
 D_3     & 3 & -1       & 0        & 0         \\ \hline
\end{array}
$$

### 1.F.

The group is a subset of $$ S_4 $$, with the following conjugacy classes.
- {e},
- {(13)(24)},
- {(13), (24)},
- {(12)(34), (14)(23)},
- {(1234), (4321)}.

Below is the character table.

$$
\begin{array}
\hline
 \text{}    & e & (13)(24) & (13)     & (12)(34) & (1234)    \\ \hline
 D_1        & 1 & 1        & 1        & 1        & 1         \\ \hline
 D_{1'}     & 1 & 1        & 1        & -1       & -1        \\ \hline
 D_{1''}    & 1 & 1        & -1       & 1        & -1        \\ \hline
 D_{1'''}   & 1 & 1        & -1       & -1       & 1         \\ \hline
 D_2        & 2 & -2       & 0        & 0        & 0         \\ \hline
\end{array}
$$

The $$ D_2 $$ representation is as follows.
- $$ \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} $$,
- $$ \begin{bmatrix} -1 & 0 \\ 0 & -1 \end{bmatrix} $$,
- $$ \begin{bmatrix} 0 & -1 \\ -1 & 0 \end{bmatrix} $$, $$ \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} $$
- $$ \begin{bmatrix} -1 & 0 \\ 0 & 1 \end{bmatrix} $$, $$ \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix} $$,
- $$ \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} $$, $$ \begin{bmatrix} 0 & 1 \\ -1 & 0 \end{bmatrix} $$.

The representation that describes the system is $$ D_4 \otimes D_2 $$, where $$ D_4 $$ is the defining representation. Its character table
is as follows.

$$
\begin{array}
\hline
 \text{} & e & (13)(24) & (13)     & (12)(34) & (1234)    \\ \hline
 D_8     & 8 & 0        & 0        & 0        & 0         \\ \hline
\end{array}
$$

Applying (1.88), we see that in $$ D_8 $$, $$ D_1 $$, $$ D_{1'} $$, $$ D_{1''} $$, and $$ D_{1'''} $$ each appears once, while $$ D_2 $$ appears twice.

The projection onto $$ D_1 $$ is

$$
\begin{eqnarray}
  P_1 &=& \frac{1}{8} \sum_{g \in G} \chi_1 (g)^* D_8(g)    \nonumber \\
  &=& \frac{1}{8} \begin{bmatrix} 1 & 1 & -1 & 1 & -1 & -1 & 1 & -1 \end{bmatrix} ^T \begin{bmatrix} 1 & 1 & -1 & 1 & -1 & -1 & 1 & -1 \end{bmatrix},
\end{eqnarray}
$$

the so-called "breathing mode".

The projection onto $$ D_{1'} $$ is

$$
\begin{eqnarray}
  P_{1'} &=& \frac{1}{8} \sum_{g \in G} \chi_{1'} (g)^* D_8(g)    \nonumber \\
  &=& \frac{1}{8} \begin{bmatrix} 1 & 1 & 1 & -1 & -1 & -1 & -1 & 1 \end{bmatrix} ^T \begin{bmatrix} 1 & 1 & 1 & -1 & -1 & -1 & -1 & 1 \end{bmatrix},
\end{eqnarray}
$$

where 1 and 3 are pulled away from each other while 2 and 4 are pushed towards each other (or the opposite).

The projection onto $$ D_{1''} $$ is

$$
\begin{eqnarray}
  P_{1''} &=& \frac{1}{8} \sum_{g \in G} \chi_{1''} (g)^* D_8(g)    \nonumber \\
  &=& \frac{1}{8} \begin{bmatrix} 1 & -1 & -1 & -1 & -1 & 1 & 1 & 1 \end{bmatrix} ^T \begin{bmatrix} 1 & -1 & -1 & -1 & -1 & 1 & 1 & 1 \end{bmatrix},
\end{eqnarray}
$$

where the four points are pulled away from each other horizontally but pushed towards each other vertically (or the opposite).

The projection onto $$ D_{1'''} $$ is

$$
\begin{eqnarray}
  P_{1'''} &=& \frac{1}{8} \sum_{g \in G} \chi_{1'''} (g)^* D_8(g)    \nonumber \\
  &=& \frac{1}{8} \begin{bmatrix} 1 & -1 & 1 & 1 & -1 & 1 & -1 & -1 \end{bmatrix} ^T \begin{bmatrix} 1 & -1 & 1 & 1 & -1 & 1 & -1 & -1 \end{bmatrix},
\end{eqnarray}
$$

which describes a rotation around the center.

The projection onto $$ D_2 $$ is

$$
\begin{eqnarray}
  P_2 &=& \frac{1}{8} \sum_{g \in G} \chi_2
   (g)^* D_8(g)    \nonumber \\
  &=& \frac{1}{4} \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} \otimes I_4,
\end{eqnarray}
$$

where $$ I_4 $$ is the four-dimensional identity matrix. It is equal to the sum of two matrices similar to (1.122) and (1.123), which describe
translations in the $$ x $$ direction and translations in the $$ y $$ direction.

## Chapter 2

### 2.A.

Taylor expanding $$ e^{i \alpha A} $$ and noticing that $$ A^n = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 1 \end{bmatrix} $$
with $$ n = 2, 4, \dots $$ while $$ A^n = A $$ with $$ n = 1, 3, \dots $$, we have

$$
\begin{eqnarray}
  e^{i \alpha A} &=& I - A^2 + A^2 + i \alpha A - \frac{\alpha^2 A^2}{2!} - \frac{i \alpha^2 A^3}{3!} + \cdots    \nonumber \\
  &=& I - A^2 + A^2 \cos \alpha + i A \sin \alpha    \nonumber \\
  &=& \begin{bmatrix} \cos \alpha & 0 & i \sin \alpha \\ 0 & 1 & 0 \\ i \sin \alpha & 0 & \cos \alpha \end{bmatrix}.
\end{eqnarray}
$$

### 2.B.

Applying (2.44), we have

$$
\begin{eqnarray}
  &&  e^{i \alpha A} B e^{-i \alpha A}    \nonumber \\
  &=& B + i \alpha [A, B] - \frac{\alpha^2}{2} [A, [A, B]] - \frac{i \alpha^3}{3!} [A, [A, [A, B]]] + \cdots    \nonumber \\
  &=& B + i \alpha B - \frac{\alpha^2}{2} B - \frac{i \alpha^3}{3!} B + \cdots    \nonumber \\
  &=& B e^{i \alpha}.
\end{eqnarray}
$$

### 2.C.

To save some space, let's notate $$ \alpha_a X_a $$ as $$ A $$ and $$ \beta_a X_a $$ as $$ B $$.

We have

$$
\begin{eqnarray}
  K &=& e^{i A} e^{i B} - 1    \nonumber \\
  &=& (1 + i A - \frac{1}{2} A^2 - \frac{i}{3!} A^3 + \cdots)    \nonumber \\
  &&  (1 + i B - \frac{1}{2} B^2 - \frac{i}{3!} B^3 + \cdots) -1    \nonumber \\
  &=& i A + i B - A B - \frac{1}{2} A^2 - \frac{1}{2} B^2    \nonumber \\
  &&  - \frac{i}{3!} A^3 - \frac{i}{3!} B^3 - \frac{i}{2} A A B - \frac{i}{2} A B B + \cdots.    \nonumber \\
\end{eqnarray}
$$

This gives

$$
\begin{eqnarray}
  i \delta_a X_a &=& K - \frac{1}{2} K^2 + \frac{1}{3} K^3    \nonumber \\
  &=& i A + i B - A B - \frac{1}{2} A^2 - \frac{1}{2} B^2    \nonumber \\
  &&  - \frac{i}{3!} A^3 - \frac{i}{3!} B^3 - \frac{i}{2} A A B - \frac{i}{2} A B B    \nonumber \\
  &&  + \frac{1}{2}(A + B)^2 + \frac{i}{2} A A B + \frac{i}{2} A B A + \frac{i}{2} B A B + \frac{i}{2} A B B    \nonumber \\
  &&  + \frac{i}{2} A^3 + \frac{i}{2} B^3 + \frac{i}{4} A B B + \frac{i}{4} B A A + \frac{i}{4} A A B + \frac{i}{4} B B A     \nonumber \\
  &&  - \frac{i}{3} (A + B)^3 + \cdots     \nonumber \\
  &=& i A + i B - \frac{1}{2} [A, B] + \frac{i}{12} [[A, B], A - B] + \cdots     \nonumber \\
  &=& i X_a \left( \alpha_a + \beta_a - \frac{1}{2} \alpha_r \beta_s f_{rsa} - \frac{1}{12} \alpha_r \beta_s (\alpha_m - \beta_m) f_{rst} f_{tma} \right) + \cdots.     \nonumber \\
\end{eqnarray}
$$

We can now write

$$ \delta_a = \alpha_a + \beta_a - \frac{1}{2} \alpha_r \beta_s f_{rsa} - \frac{1}{12} \alpha_r \beta_s (\alpha_m - \beta_m) f_{rst} f_{tma} + \cdots. $$

## Chapter 3

### 3.A.

We start with the highest weight $$ | j + s | j + s \rangle = |j, j \rangle |s, s \rangle $$ and repeatedly apply $$ J^- $$ on both
sides until they vanish. We get the spin $$ j + s $$ representation, with in total $$ 2(j + s) + 1 $$ states.

We will notice that $$ | j + s | j + s - 1 \rangle $$ is a linear combination of
$$ |j, j - 1 \rangle |s, s \rangle $$ and $$ |j, j \rangle |s, s - 1 \rangle $$, which spans a 2-dimensional space. These two vectors
can form another linear combination that is orthogonal to $$ | j + s | j + s - 1 \rangle $$, and this second linear combination can
only be $$ | j + s - 1| j + s - 1 \rangle $$. (To verify this claim, apply $$ J^+ $$ and see it vanish.) Now we can again repeatedly
apply $$ J^- $$ on both sides until they vanish. In doing so, we get the spin $$ j + s - 1 $$ representation, with in total
$$ 2(j + s) - 1 $$ states.

Now we do exactly the same with $$ | j + s - 1 | j + s - 2 \rangle $$, which is a linear combination of three vectors, which spans a
3-dimensional space. These three vectors can form a third linear combination that is orthogonal to both $$ | j + s | j + s - 2 \rangle $$
and $$ | j + s - 1 | j + s - 2 \rangle $$. This third linear combination can only be $$ | j + s - 2 | j + s - 2 \rangle $$...

The whole process stops at the spin $$ | j - s | $$ representation.

As a sanity check, both sides of the equation have $$ (2 j + 1) (2 s + 1) $$ linearly independent states. So everything works out.

### 3.B.

It is easy to show that there is a similarity transformation $$ S $$ such that

$$ S^{-1} (\hat{r} \cdot \sigma) S = \sigma_3. $$

We have

$$
\begin{eqnarray}
  && e^{i \vec{r} \cdot \vec{\sigma}}    \nonumber \\
  &=& S e^{i |\vec{r}| \sigma_3} S^{-1}    \nonumber \\
  &=& S \begin{bmatrix} e^{i |\vec{r}|} & 0 \\ 0 & e^{-i |\vec{r}|} \end{bmatrix} S^{-1}    \nonumber \\
\end{eqnarray}
$$

### 3.C.

Let $$ S = \begin{bmatrix} \frac{1}{\sqrt{2}} & 0 & -\frac{1}{\sqrt{2}} \\ \frac{i}{\sqrt{2}} & 0 & \frac{i}{\sqrt{2}} \\ 0 & -1 & 0 \end{bmatrix} $$.

It is easy to verify that $$ J_i^1 = S^{-1} T_i S $$, where $$ J_i^1 $$ and $$ T_i $$ are the spin-1 representation and the adjoint
representation of the $$ i $$-th generator.

### 3.D.

$$
\begin{bmatrix}
  0 & 0 & 0 & -i \\
  0 & 0 & -i & 0 \\
  0 & i & 0 & 0 \\
  i & 0 & 0 & 0
\end{bmatrix}
$$.

### 3.E.

(a) $$ [\sigma_a, \sigma_b] \eta_c $$

(b) $$ \mathrm{Tr}(\sigma_a \cdot 2 \delta_{bd} I \sigma_c) = 4 \delta_{bd} \mathrm{Tr}(\delta_{ac} I) = 8 \delta_{ac} \delta_{bd} $$

(c) $$ \sigma_1 \sigma_2 \eta_1 \eta_2 - \sigma_2 \sigma_1 \eta_2 \eta_1 = 0 $$